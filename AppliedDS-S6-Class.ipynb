{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <center> **Introduction to Applied Data Science**\n",
    "\n",
    "### <center> *Prof. Bahram Mobasher*\n",
    "#### <center> Teaching Assistant: *[Sina Taamoli](https://sinataamoli.github.io/)* | email: *sina.taamoli@email.ucr.edu*\n",
    "### <center> **Week 6: Naive Bayes**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb908ef2",
   "metadata": {},
   "source": [
    "## Naive Bayes spam filtering\n",
    "\n",
    "Consider that you are given a data set of text messages which are labeled with ham or spam. We will use a training sample with ~4000 text messages, but first let’s consider a few examples to get familiar with the naive Bayes idea. <br>\n",
    "<center>\n",
    "\n",
    "| Class | Message | Bag of words |\n",
    "| -------- | -------- | -------- |\n",
    "| Spam   | Send us your password   | send, password   |\n",
    "| Ham   | I will send you the letter   | send, letter   |\n",
    "| Ham   | I wrote a letter   | write, letter   | <br>\n",
    "</center>\n",
    "\n",
    "We want to compute P(Spam|Bag of words). Last session, we learned from Bayes’ rule: <br>\n",
    "\n",
    "$P(Spam | \\text{Bag of words}) = \\frac{P(\\text{Bag of words}|Spam)P(Spam)}{P(\\text{Bag of words}|Spam)P(Spam)+P(\\text{Bag of words}|Ham)P(Ham)}$ <br>\n",
    "\n",
    "P(word|spam) and P(word|ham) can be estimated from the training sample. To avoid zero probabilities, we consider the initial value of 1 for the number of occurence of a word. Note that the priors are P(ham)=2/3 and P(spam)=1/3. <br>\n",
    "\n",
    "\n",
    "<center>\n",
    "\n",
    "| Spam | Ham | Word | Spam(i=1) | Ham(i=1) |\n",
    "| -------- | -------- | -------- | -------- | -------- |\n",
    "| $\\frac{1}{2}$   | $\\frac{1}{4}$   | send   | $\\frac{1+1}{2+4}$ | $\\frac{1+1}{4+4}$ |\n",
    "| $\\frac{1}{2}$   | $\\frac{0}{4}$   | password   | $\\frac{1+1}{2+4}$ | $\\frac{0 + 1}{4+4}$ |\n",
    "$\\frac{0}{2}$| $\\frac{2}{4}$   | letter   | $\\frac{0+1}{2+4}$   | $\\frac{2+1}{4+4}$ |  |\n",
    "| $\\frac{0}{2}$   | $\\frac{1}{4}$   | write   | $\\frac{0+1}{2+4}$ | $\\frac{1+1}{4+4}$ |\n",
    "\n",
    "</center> <br>\n",
    "\n",
    "Now, consider a new text message “write your password in the password box”. We don’t have the word “box” in our training sample, so the safe choice would be to remove this from the bag of words and make decision based on on the other two words, “write” and “password”. “password” occured twice. <br>\n",
    "\n",
    "$P(spam|write,password,password) = \\frac{P(write|spam)P(password|spam)P(password|spam)P(spam)}{P(write|Spam)P(password|Spam)P(password|spam)P(Spam)+P(write|ham)P(password|ham)P(password|ham)P(ham)}$ <br>\n",
    "\n",
    "$P(spam|write,password,password) = \\frac{\\frac{1}{6} \\times \\frac{2}{6} \\times \\frac{2}{6} \\times \\frac{1}{3}}{\\frac{1}{6} \\times \\frac{2}{6} \\times \\frac{2}{6} \\times \\frac{1}{3} + \\frac{2}{8} \\times \\frac{1}{8} \\times \\frac{1}{8} \\times \\frac{2}{3}} \\sim 70\\%$ <br>\n",
    "\n",
    "and $P(ham|write,password,password) = 1 − P(spam|write,password,password) = 30\\%$, so we classify this email as a spam message. This was just a demonsteration of the naive Bayes method. Let’s use a large data set to build a model and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b62baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f5b3f",
   "metadata": {},
   "source": [
    "NLTK (Natural Language Toolkit) is a set of libraries for Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b77a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sinataamoli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8ffa36",
   "metadata": {},
   "source": [
    "Stop words are the most common words in a language which don’t carry much information. We will filter them before NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e96a5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c64603",
   "metadata": {},
   "source": [
    "A word can have many variations with the same meaning. So, we will use stem package to normalize the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8928002c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cook', 'cook', 'cook')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "Ps = PorterStemmer()\n",
    "Ps.stem('cook'), Ps.stem('cooking'), Ps.stem('cooked')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67687308",
   "metadata": {},
   "source": [
    "We also need to remove punctuations, they are not informative in our classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d257e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "punctuations = string.punctuation\n",
    "print(punctuations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52950a0d",
   "metadata": {},
   "source": [
    "Let’s load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f6fd868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('spam.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc37971",
   "metadata": {},
   "source": [
    "Change categorical data into numbers which can be processed in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ham\n",
       "1        ham\n",
       "2       spam\n",
       "3        ham\n",
       "4        ham\n",
       "        ... \n",
       "5164    spam\n",
       "5165     ham\n",
       "5166     ham\n",
       "5167     ham\n",
       "5168     ham\n",
       "Name: Class, Length: 5169, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9630e5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text  Class_code\n",
       "0   ham  Go until jurong point, crazy.. Available only ...           0\n",
       "1   ham                      Ok lar... Joking wif u oni...           0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...           1\n",
       "3   ham  U dun say so early hor... U c already then say...           0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...           0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class_code'] = pd.get_dummies(data.Class, drop_first=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7a732e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataframe, test_size = 0.3, rs = None):\n",
    "    \"\"\"\n",
    "    A function which takes pandas dataframe and split it to train and test samples\n",
    "    \"\"\" \n",
    "    dataframe_test = dataframe.sample(frac = test_size, random_state = rs)\n",
    "    dataframe_train = dataframe.loc[dataframe.index.difference(dataframe_test.index)]\n",
    "    return (dataframe_train.reset_index(drop=True), dataframe_test.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95d0622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size = 0.3, rs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bf27fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text  Class_code\n",
       "0   ham                      Ok lar... Joking wif u oni...           0\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...           1\n",
       "2   ham  U dun say so early hor... U c already then say...           0\n",
       "3   ham  Nah I don't think he goes to usf, he lives aro...           0\n",
       "4  spam  FreeMsg Hey there darling it's been 3 week's n...           1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "beff6372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just looked it up and addie goes back Monday, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>You best watch what you say cause I get drunk ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Me i'm not workin. Once i get job...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yar lor... How u noe? U used dat route too?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Under the sea, there lays a rock. In the rock,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text  Class_code\n",
       "0   ham  Just looked it up and addie goes back Monday, ...           0\n",
       "1   ham  You best watch what you say cause I get drunk ...           0\n",
       "2   ham               Me i'm not workin. Once i get job...           0\n",
       "3   ham        Yar lor... How u noe? U used dat route too?           0\n",
       "4   ham  Under the sea, there lays a rock. In the rock,...           0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130ce0e",
   "metadata": {},
   "source": [
    "Cleaning up one of the text messages as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41222cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wah lucky man... Then can save money... Hee...\n"
     ]
    }
   ],
   "source": [
    "message = data_train.Text[46]\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b1ebe72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wah lucky man Then can save money Hee\n"
     ]
    }
   ],
   "source": [
    "message = ''.join([x for x in message if x not in punctuations])\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6d97bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wah', 'lucky', 'man', 'Then', 'can', 'save', 'money', 'Hee']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51cae828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wah', 'lucky', 'man', 'Then', 'save', 'money', 'Hee']\n"
     ]
    }
   ],
   "source": [
    "message = [x for x in message.split() if x not in stopwords]\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "539f531e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wah', 'lucki', 'man', 'then', 'save', 'money', 'hee']\n"
     ]
    }
   ],
   "source": [
    "message=[Ps.stem(x) for x in message]\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59325e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'wah': 1, 'lucki': 1, 'man': 1, 'then': 1, 'save': 1, 'money': 1, 'hee': 1})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293ecbcc",
   "metadata": {},
   "source": [
    "Now put them together in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12abf0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message(message):\n",
    "    \"\"\"\n",
    "    a function to clean up message and return a dict with bag of their occurence rate\n",
    "    \"\"\"\n",
    "    message = message.lower()\n",
    "    message = ''.join([x for x in message if x not in punctuations])\n",
    "    message = [x for x in message.split() if x not in stopwords]\n",
    "    message=[Ps.stem(x) for x in message]\n",
    "    \n",
    "    return (Counter(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c84d7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "Counter({'date': 1, 'sunday': 1})\n"
     ]
    }
   ],
   "source": [
    "print(data_train.Text[10])\n",
    "print(clean_message(data_train.Text[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47270ce9",
   "metadata": {},
   "source": [
    "Apply the function to all the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b25d6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class_code</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'ok': 1, 'lar': 1, 'joke': 1, 'wif': 1, 'u': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'free': 1, 'entri': 2, '2': 1, 'wkli': 1, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'u': 2, 'dun': 1, 'say': 2, 'earli': 1, 'hor'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'nah': 1, 'dont': 1, 'think': 1, 'goe': 1, 'u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'freemsg': 1, 'hey': 1, 'darl': 1, '3': 1, 'w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text  Class_code  \\\n",
       "0   ham                      Ok lar... Joking wif u oni...           0   \n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...           1   \n",
       "2   ham  U dun say so early hor... U c already then say...           0   \n",
       "3   ham  Nah I don't think he goes to usf, he lives aro...           0   \n",
       "4  spam  FreeMsg Hey there darling it's been 3 week's n...           1   \n",
       "\n",
       "                                        bag_of_words  \n",
       "0  {'ok': 1, 'lar': 1, 'joke': 1, 'wif': 1, 'u': ...  \n",
       "1  {'free': 1, 'entri': 2, '2': 1, 'wkli': 1, 'co...  \n",
       "2  {'u': 2, 'dun': 1, 'say': 2, 'earli': 1, 'hor'...  \n",
       "3  {'nah': 1, 'dont': 1, 'think': 1, 'goe': 1, 'u...  \n",
       "4  {'freemsg': 1, 'hey': 1, 'darl': 1, '3': 1, 'w...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['bag_of_words'] = data_train['Text'].apply(clean_message)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b058f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "bows = data_train.bag_of_words\n",
    "bows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "bows_ham = \n",
    "bows_spam = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57afb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "bows_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9472490",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_occurence_ham = {key:1 for key in words} # Initializing all words by occurance=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115aae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_occurence_ham['soon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_occurence_spam={key:1 for key in words}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ef377",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_occurence_spam['free']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed6917",
   "metadata": {},
   "source": [
    "Probability of a word given that the text is ham/spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_occurence_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_word_h={}\n",
    "P_word_s={}\n",
    "for key in number_of_occurence_ham:\n",
    "    \n",
    "for key in number_of_occurence_spam:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bcfc10",
   "metadata": {},
   "source": [
    "Finding the priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037cd4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_h=\n",
    "P_s="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e60315",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(P_s)\n",
    "print(P_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7df86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(document):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "classifier=np.vectorize(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b2612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier('congratulations! you won $500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ced2bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(\"Let's apply this model to the test sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94daf2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier(data_test.Text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023438af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f945975",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = data_test.Class_code\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75990e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, TN, FP, FN = 0, 0, 0, 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb60419",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e01668",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([[TP,FP],[FN,TN]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8463e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=TP/(TP+FP)\n",
    "print(\"precision=\",precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce41d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall=TP/(TP+FN)\n",
    "print(\"recall=\",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c38a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_score=2*precision*recall/(precision+recall)\n",
    "print(\"F1_score=\",F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893601c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=(TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"accuracy=\",accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
